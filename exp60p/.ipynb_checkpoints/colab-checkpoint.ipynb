{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CnsrarsqYlS2"
   },
   "source": [
    "### 必要なライブラリのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MvX8sNWx8Zuw"
   },
   "outputs": [],
   "source": [
    "!pip install pysoundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JeGAgHb4YQu2"
   },
   "source": [
    "### データのダウンロード・展開（3分程度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xNzuX18K-M5c"
   },
   "outputs": [],
   "source": [
    "!date\n",
    "\n",
    "!mkdir -p data/wave\n",
    "!wget -q http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz -O data/wave.tar.gz\n",
    "!tar xzf data/wave.tar.gz -C data/wave\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C7J61akcm4ij"
   },
   "source": [
    "### MFCC特徴量の抽出（数分～数十分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRc5rlaAjBY1"
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import logging\n",
    "import argparse\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "import random\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "DATA_ROOT = \"data\"\n",
    "MODEL_DIR = \"model\"\n",
    "\n",
    "training_userate = 60.0\n",
    "validation_userate = 10.0\n",
    "\n",
    "wavedir       = DATA_ROOT + \"/wave/\"\n",
    "txtdir        = DATA_ROOT + \"/\"\n",
    "mfccdir       = DATA_ROOT + \"/mfcc/\"\n",
    "datalist      = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "SAMPLING_RATE = 16000\n",
    "MFCC_DIM      = 13\n",
    "\n",
    "# This function is the same as the code in README.md of speech_commands\n",
    "MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "  \"\"\"Determines which data partition the file should belong to.\n",
    "  We want to keep files in the same training, validation, or testing sets even\n",
    "  if new ones are added over time. This makes it less likely that testing\n",
    "  samples will accidentally be reused in training when long runs are restarted\n",
    "  for example. To keep this stability, a hash of the filename is taken and used\n",
    "  to determine which set it should belong to. This determination only depends on\n",
    "  the name and the set proportions, so it won't change as other files are added.\n",
    "  It's also useful to associate particular files as related (for example words\n",
    "  spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "  ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "  'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "  Args:\n",
    "    filename: File path of the data sample.\n",
    "    validation_percentage: How much of the data set to use for validation.\n",
    "    testing_percentage: How much of the data set to use for testing.\n",
    "  Returns:\n",
    "    String, one of 'training', 'validation', or 'testing'.\n",
    "  \"\"\"\n",
    "  base_name = os.path.basename(filename)\n",
    "  # We want to ignore anything after '_nohash_' in the file name when\n",
    "  # deciding which set to put a wav in, so the data set creator has a way of\n",
    "  # grouping wavs that are close variations of each other.\n",
    "  hash_name = re.sub(r'_nohash_.*$', '', base_name).encode('utf-8')\n",
    "  # This looks a bit magical, but we need to decide whether this file should\n",
    "  # go into the training, testing, or validation sets, and we want to keep\n",
    "  # existing files in the same set even if more files are subsequently\n",
    "  # added.\n",
    "  # To do that, we need a stable way of deciding based on just the file name\n",
    "  # itself, so we do a hash of that and then use that to generate a\n",
    "  # probability value that we use to assign it.\n",
    "  hash_name_hashed = hashlib.sha1(hash_name).hexdigest()\n",
    "  percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                      (MAX_NUM_WAVS_PER_CLASS + 1)) *\n",
    "                     (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "  if percentage_hash < validation_percentage:\n",
    "    result = 'validation'\n",
    "  elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "    result = 'testing'\n",
    "  else:\n",
    "    result = 'training'\n",
    "  return result\n",
    "\n",
    "\n",
    "logging.info('Start making mfcc')\n",
    "os.makedirs(txtdir, exist_ok=True)\n",
    "os.makedirs(mfccdir, exist_ok=True)\n",
    "training_list   = []\n",
    "testing_list    = []\n",
    "validation_list = []\n",
    "result = {}\n",
    "\n",
    "if os.path.exists(mfccdir+'mfcc.pkl'):\n",
    "    logging.info('mfcc data is already prepared')\n",
    "    exit()\n",
    "\n",
    "for command in datalist:\n",
    "    for wavfile in os.listdir(wavedir+command):\n",
    "        partition = which_set(wavfile, 10, 10)  # divide to \"training\", \"validation\", \"testing\" 3 parts\n",
    "        filepath = command+'/'+wavfile\n",
    "        if partition == 'training':\n",
    "            training_list.append(filepath)\n",
    "        if partition == 'testing':\n",
    "            testing_list.append(filepath)\n",
    "        if partition == 'validation':\n",
    "            validation_list.append(filepath)\n",
    "          \n",
    "training_list = random.sample(training_list, int(len(training_list)*(training_userate / 100.0)))\n",
    "validation_list = random.sample(validation_list, int(len(validation_list)*(validation_userate / 100.0)))\n",
    "\n",
    "for filename in training_list + testing_list + validation_list:\n",
    "    audio, sr = sf.read(wavedir+filename)\n",
    "    mfcc      = librosa.feature.mfcc(audio, sr=SAMPLING_RATE, n_mfcc=MFCC_DIM, n_fft=400, hop_length=160)  # extract mfcc featur\n",
    "    mfcc      = np.asarray(mfcc, dtype=np.float32)  # change format to np.float32e\n",
    "    result[filename] = mfcc.T\n",
    "    \n",
    "with open(txtdir+'train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(training_list))\n",
    "with open(txtdir+'eval.txt', 'w') as f:\n",
    "    f.write('\\n'.join(testing_list))\n",
    "with open(txtdir+'valid.txt', 'w') as f:\n",
    "    f.write('\\n'.join(validation_list))\n",
    "    \n",
    "with open(mfccdir+'mfcc.pkl', 'wb') as f:\n",
    "    pickle.dump(result, f)\n",
    "    \n",
    "logging.info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tuIQeld63eaX"
   },
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xr6O4fsC3aoi"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# This model classifies input audio to some classes.\n",
    "# The structure is stacked biLSTM followed by an inference layer.\n",
    "# The inference layer receives context vector of the encoder.\n",
    "\n",
    "# in_size:     Input feature dimension, typically corresponds with MFCC dimension.\n",
    "# num_class:   The number of classes to infer.\n",
    "# hidden_size: The number of one side of encoder-lstm nodes.\n",
    "#              The encoder is stacked biLSTM, so encoder-outputs dimension is 2*hidden_size.\n",
    "# num_stack:   How many lstms in the encoder are stacked. \n",
    "# dropout:     Dropout ratio. This is known to be effective for overfitting.\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_size, num_class, hidden_size, num_stack, dropout):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder   = nn.LSTM(in_size, hidden_size, num_stack, batch_first=True, bidirectional=True, dropout=dropout)\n",
    "        self.inferring = nn.Linear(hidden_size*2, num_class)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        _, (h, c) = self.encoder(inputs)\n",
    "\n",
    "        # Concatenate forward and backward LSTM's context vector\n",
    "        context              = torch.cat((h[-2,:], h[-1,:]), dim=1)\n",
    "        return self.inferring(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzUS9Doj4iRv"
   },
   "source": [
    "### （その他関数定義）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCNcAbTC4v-X"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "command_list   = ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "\n",
    "def Apply_cmvn(inputs): # apply cepstral mean and variance normalization\n",
    "    batch_size, time, dim = inputs.shape\n",
    "    mu    = torch.mean(inputs, dim=1).repeat(1, time).reshape(batch_size, time, dim)\n",
    "    sigma = torch.pow(torch.mean(torch.pow(inputs, 2), dim=1).repeat(1, time).reshape(batch_size, time, dim) - torch.pow(mu, 2), 0.5)\n",
    "    return (inputs - mu) / sigma\n",
    "\n",
    "def insert_index_descending_order(query, num_list):\n",
    "    matching_list = list(filter(lambda x: x < query, num_list)) # list(filter(if x < query for x in num_list))\n",
    "    if len(matching_list) == 0:\n",
    "        return len(num_list)\n",
    "    else:\n",
    "        return num_list.index(matching_list[0])\n",
    "    \n",
    "mfcc_dict = None\n",
    "\n",
    "def Batch_generator(mfcc_root, dataset, batch_size): # data batch generator\n",
    "    global mfcc_dict\n",
    "    if mfcc_dict is None:\n",
    "        with open(mfcc_root+'/mfcc.pkl', 'rb') as f:\n",
    "            mfcc_dict = pickle.load(f)\n",
    "\n",
    "    datalist_txt = open(dataset, 'r')\n",
    "\n",
    "    datalist      = datalist_txt.read().strip().split('\\n')\n",
    "    shuffled_data = random.sample(datalist, len(datalist))\n",
    "    datalist_txt.close()\n",
    "    epoch         = 1\n",
    "\n",
    "    while True:\n",
    "        data_batch   = np.array([], dtype=np.float32)\n",
    "        label_batch  = []\n",
    "        length_batch = []\n",
    "        MAX_LEN      = 0\n",
    "        for i in range(batch_size):\n",
    "            sample  = shuffled_data.pop() # pop data from shuffled dataset\n",
    "            label   = sample.split('/')[0]\n",
    "            mfcc    = mfcc_dict[sample]\n",
    "            MAX_LEN = len(mfcc) if MAX_LEN < len(mfcc) else MAX_LEN # find max len in a batch\n",
    "            index   = insert_index_descending_order(len(mfcc), length_batch) # insert data to get the decending sequence (for latter pack_padded_sequence)\n",
    "            if i == 0:\n",
    "                data_batch = np.asarray([mfcc])\n",
    "            else:\n",
    "                data_batch = np.pad(data_batch, ((0, 0), (0, MAX_LEN - data_batch.shape[1]), (0, 0)), mode='constant', constant_values=0)\n",
    "                data_batch = np.insert(data_batch, index, np.pad(mfcc, ((0, MAX_LEN - len(mfcc)), (0, 0)), mode='constant', constant_values=0), axis=0)\n",
    "            label_batch.insert(index, command_list.index(label)) # add to current batch\n",
    "            length_batch.insert(index, len(mfcc))\n",
    "        data_batch  = np.asarray(data_batch,  dtype=np.float32) # format change\n",
    "        label_batch = np.asarray(label_batch, dtype=np.int64)\n",
    "\n",
    "        if len(shuffled_data) < batch_size: # if remaining data (wait for pop into the batch) is not enough, do extension\n",
    "            shuffled_data = random.sample(datalist, len(datalist)) + shuffled_data\n",
    "            epoch        += 1\n",
    "\n",
    "        yield data_batch, label_batch, length_batch, epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py9K55Th02bK"
   },
   "source": [
    "### モデルの学習（数分～数時間）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2gKoJmvxmEw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "DATA_ROOT = \"data\"\n",
    "MODEL_DIR = \"model\"\n",
    "\n",
    "IN_SIZE       = 13\n",
    "NUM_CLASS     = 10\n",
    "HIDDEN_SIZE   = 128\n",
    "NUM_STACK     = 5\n",
    "DROPOUT       = 0.5\n",
    "USE_CMVN      = False\n",
    "MAX_ITERATION = 1000000\n",
    "MAX_EPOCH     = 100\n",
    "BATCH_SIZE    = 256\n",
    "MFCC_ROOT     = DATA_ROOT + \"/mfcc\"\n",
    "TRAIN_LIST    = DATA_ROOT + \"/train.txt\"\n",
    "VALID_LIST    = DATA_ROOT + \"/valid.txt\"\n",
    "SAVE_FILE     = MODEL_DIR + \"/trained.model\"\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Build up model and batch generator\n",
    "device      = 'cuda' if torch.cuda.is_available() else 'cpu'  # check available gpu\n",
    "model       = Classifier(IN_SIZE, NUM_CLASS, HIDDEN_SIZE, NUM_STACK, DROPOUT).to(device) # build up model\n",
    "loss_fun    = nn.CrossEntropyLoss() # define CE as loss function (objective function)\n",
    "optimizer   = torch.optim.Adam(model.parameters()) # define optimizer (choosed adam here, you can try others as well)\n",
    "batch_train = Batch_generator(MFCC_ROOT, TRAIN_LIST, BATCH_SIZE) # batch generator\n",
    "batch_valid = Batch_generator(MFCC_ROOT, VALID_LIST, BATCH_SIZE)\n",
    "\n",
    "# print out settings\n",
    "logging.info('Batch_size: {}'.format(BATCH_SIZE))\n",
    "logging.info('Max epoch: {}'.format(MAX_EPOCH))\n",
    "logging.info('Max iteration: {}'.format(MAX_ITERATION))\n",
    "logging.info('Hidden size: {}'.format(HIDDEN_SIZE))\n",
    "logging.info('Num stack: {}'.format(NUM_STACK))\n",
    "logging.info('Use cmvn: {}'.format(USE_CMVN))\n",
    "\n",
    "# Training part\n",
    "now_epoch   = 1\n",
    "total_num   = 0 # total number of used data\n",
    "correct_num = 0 # number of corrected prediction\n",
    "acc_plt = []\n",
    "epoch_plt = []\n",
    "for iteration in range(1, MAX_ITERATION+1):\n",
    "    model.train() # train the model\n",
    "    inputs, labels, lengths, epoch = next(batch_train) # generate next batch\n",
    "    if USE_CMVN:\n",
    "        inputs  = Apply_cmvn(torch.from_numpy(inputs).to(device)) # use cmvn\n",
    "    else:\n",
    "        inputs  = torch.from_numpy(inputs).to(device)\n",
    "    inputs  = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True) #  pack the padded sequence (remove the redundancy padding)\n",
    "    labels  = torch.from_numpy(labels).to(device) # load label\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    loss    = loss_fun(outputs, labels) # compute loss\n",
    "    optimizer.zero_grad() # clear gradient for all optimized tensor (initialize with 0)\n",
    "    loss.backward() # gradient backpropagation\n",
    "    optimizer.step() # update parameters\n",
    "\n",
    "    total_num   += len(outputs) # compute total num\n",
    "    correct_num += torch.bincount(torch.abs(torch.argmax(outputs, dim=1) - labels))[0] # compute corrected num\n",
    "\n",
    "    if now_epoch < epoch: #if this iteration is final of epoch\n",
    "        now_epoch   = epoch\n",
    "        correct_num_v = 0\n",
    "        total_num_v   = 0\n",
    "\n",
    "        #validation\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            while True:\n",
    "                inputs, labels, lengths, epoch = next(batch_valid)\n",
    "\n",
    "                if USE_CMVN:\n",
    "                    inputs  = Apply_cmvn(torch.from_numpy(inputs).to(device))\n",
    "                else:\n",
    "                    inputs  = torch.from_numpy(inputs).to(device)\n",
    "                inputs  = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True)\n",
    "                labels  = torch.from_numpy(labels).to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss    = loss_fun(outputs, labels)\n",
    "                total_num_v   += len(outputs)\n",
    "                correct_num_v += torch.bincount(torch.abs(torch.argmax(outputs, dim=1) - labels))[0]\n",
    "                if epoch == now_epoch: break\n",
    "        if (now_epoch-1) % 10 == 0:\n",
    "            logging.info('[epoch {}, accuracy] training: {:.04f}, validation: {:.04f}'.format(\n",
    "                now_epoch-1, correct_num.float() / total_num, correct_num_v.float() / total_num_v)) #print validation score\n",
    "        acc_plt.append(float(\"{:.04f}\".format(correct_num_v.float() / total_num_v)))\n",
    "        epoch_plt.append(now_epoch-1)\n",
    "        correct_num = 0\n",
    "        total_num   = 0\n",
    "\n",
    "    if MAX_EPOCH < now_epoch:\n",
    "        break\n",
    "\n",
    "# plot graph epoch-accuracy.jpg\n",
    "# this shows how accuracy improved as training goes\n",
    "plt.plot(epoch_plt, acc_plt, \"ro-\")\n",
    "plt.xlabel(\"epoch number\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.savefig(\"epoch-accuracy.jpg\")\n",
    "\n",
    "logging.info('done')\n",
    "torch.save(model.state_dict(), SAVE_FILE) # save trained model\n",
    "        \n",
    "elapsed_time = time.time() - start_time\n",
    "with open('train.time.log', 'w') as f:\n",
    "    f.write('training time = {} (sec)\\n'.format(int(elapsed_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1uzLGBR_eN9"
   },
   "source": [
    "### モデルの評価（数秒程度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JrZz02i9ZRF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "IN_SIZE       = 13\n",
    "NUM_CLASS     = 10\n",
    "HIDDEN_SIZE   = 128\n",
    "NUM_STACK     = 5\n",
    "USE_CMVN      = False\n",
    "BATCH_SIZE    = 256\n",
    "PARAM_FILE    = MODEL_DIR + \"/trained.model\"\n",
    "EVAL_LIST     = DATA_ROOT + \"/eval.txt\"\n",
    "MFCC_ROOT     = DATA_ROOT + \"/mfcc\"\n",
    "\n",
    "# Build up model and batch generator\n",
    "device      = 'cuda' if torch.cuda.is_available() else 'cpu'   # check available gpu\n",
    "model       = Classifier(IN_SIZE, NUM_CLASS, HIDDEN_SIZE, NUM_STACK, 0.0).to(device) # build model (same structure as trained model)\n",
    "model.load_state_dict(torch.load(PARAM_FILE)) # load parameters from trained model\n",
    "batch_test  = Batch_generator(MFCC_ROOT, EVAL_LIST, BATCH_SIZE) # data batch generator for evaluation data\n",
    "\n",
    "# Print out setting\n",
    "logging.info('Batch_size: {}'.format(BATCH_SIZE))\n",
    "logging.info('Hidden size: {}'.format(HIDDEN_SIZE))\n",
    "logging.info('Num stack: {}'.format(NUM_STACK))\n",
    "logging.info('Use cmvn: {}'.format(USE_CMVN))\n",
    "\n",
    "# Training part\n",
    "with torch.no_grad(): # disable gradient calculation, reduce memory consumption\n",
    "    model.eval()\n",
    "    total_num   = 0 # total num of test data\n",
    "    correct_num = 0 # corrected prediction num\n",
    "    while True:\n",
    "        inputs, labels, lengths, epoch = next(batch_test) # generate a data batch\n",
    "        if USE_CMVN:\n",
    "            inputs  = Apply_cmvn(torch.from_numpy(inputs).to(device)) # use cmvn\n",
    "        else:\n",
    "            inputs  = torch.from_numpy(inputs).to(device)\n",
    "        inputs  = nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first=True) # pack the padded sequence (remove the redundancy padding)\n",
    "        labels  = torch.from_numpy(labels).to(device)\n",
    "        outputs = model(inputs)\n",
    "        total_num   += len(outputs)\n",
    "        correct_num += torch.bincount(torch.abs(torch.argmax(outputs, dim=1) - labels))[0] # compute the number of corrected prediction\n",
    "        if epoch == 2: break\n",
    "    score = correct_num.float() / total_num\n",
    "    logging.info('accuracy: {:.04f}'.format(score))\n",
    "    with open('score.txt', 'w') as f:\n",
    "        f.write('recognition rate = {:.1%}\\n'.format(score))\n",
    "\n",
    "logging.info('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSkLroty_ihN"
   },
   "source": [
    "### 結果の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKSc7lRxxh4S"
   },
   "outputs": [],
   "source": [
    "!cat train.time.log\n",
    "!cat score.txt"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tga-asr.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tttslab/tut-asr-voicecommand/blob/master/exp1p/colab.ipynb",
     "timestamp": 1568122362122
    },
    {
     "file_id": "https://github.com/tttslab/tut-asr-voicecommand/blob/master/exp1p/colab.ipynb",
     "timestamp": 1561321231982
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
